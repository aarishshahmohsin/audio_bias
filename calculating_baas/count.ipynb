{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T05:36:08.251951Z",
     "iopub.status.busy": "2024-12-26T05:36:08.251658Z",
     "iopub.status.idle": "2024-12-26T05:36:10.758305Z",
     "shell.execute_reply": "2024-12-26T05:36:10.757487Z",
     "shell.execute_reply.started": "2024-12-26T05:36:08.251928Z"
    },
    "id": "czWK_6mTopAk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## This script is based on the https://github.com/TaoRuijie/ECAPA-TDNN/blob/main/model.py\n",
    "## I made some changes to the original code for training a binary classifier.\n",
    "\n",
    "from typing import Optional\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchaudio\n",
    "from torchaudio.functional import resample\n",
    "\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels : int , bottleneck : int = 128) -> None:\n",
    "        super(SEModule, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Conv1d(channels, bottleneck, kernel_size=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm1d(bottleneck), # I remove this layer\n",
    "            nn.Conv1d(bottleneck, channels, kernel_size=1, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "            )\n",
    "\n",
    "    def forward(self, input : torch.Tensor) -> torch.Tensor:\n",
    "        x = self.se(input)\n",
    "        return input * x\n",
    "\n",
    "class Bottle2neck(nn.Module):\n",
    "    def __init__(self, inplanes : int, planes : int, kernel_size : Optional[int] = None, dilation : Optional[int] = None, scale : int = 8) -> None:\n",
    "        super(Bottle2neck, self).__init__()\n",
    "        width       = int(math.floor(planes / scale))\n",
    "        self.conv1  = nn.Conv1d(inplanes, width*scale, kernel_size=1)\n",
    "        self.bn1    = nn.BatchNorm1d(width*scale)\n",
    "        self.nums   = scale -1\n",
    "        convs       = []\n",
    "        bns         = []\n",
    "        num_pad = math.floor(kernel_size/2)*dilation\n",
    "        for i in range(self.nums):\n",
    "            convs.append(nn.Conv1d(width, width, kernel_size=kernel_size, dilation=dilation, padding=num_pad))\n",
    "            bns.append(nn.BatchNorm1d(width))\n",
    "        self.convs  = nn.ModuleList(convs)\n",
    "        self.bns    = nn.ModuleList(bns)\n",
    "        self.conv3  = nn.Conv1d(width*scale, planes, kernel_size=1)\n",
    "        self.bn3    = nn.BatchNorm1d(planes)\n",
    "        self.relu   = nn.ReLU()\n",
    "        self.width  = width\n",
    "        self.se     = SEModule(planes)\n",
    "\n",
    "    def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        spx = torch.split(out, self.width, 1)\n",
    "        for i in range(self.nums):\n",
    "          if i==0:\n",
    "            sp = spx[i]\n",
    "          else:\n",
    "            sp = sp + spx[i]\n",
    "          sp = self.convs[i](sp)\n",
    "          sp = self.relu(sp)\n",
    "          sp = self.bns[i](sp)\n",
    "          if i==0:\n",
    "            out = sp\n",
    "          else:\n",
    "            out = torch.cat((out, sp), 1)\n",
    "        out = torch.cat((out, spx[self.nums]),1)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = self.se(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class ECAPA_gender(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, C : int = 1024):\n",
    "        super(ECAPA_gender, self).__init__()\n",
    "        self.C = C\n",
    "        self.conv1  = nn.Conv1d(80, C, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu   = nn.ReLU()\n",
    "        self.bn1    = nn.BatchNorm1d(C)\n",
    "        self.layer1 = Bottle2neck(C, C, kernel_size=3, dilation=2, scale=8)\n",
    "        self.layer2 = Bottle2neck(C, C, kernel_size=3, dilation=3, scale=8)\n",
    "        self.layer3 = Bottle2neck(C, C, kernel_size=3, dilation=4, scale=8)\n",
    "        # I fixed the shape of the output from MFA layer, that is close to the setting from ECAPA paper.\n",
    "        self.layer4 = nn.Conv1d(3*C, 1536, kernel_size=1)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(4608, 256, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Tanh(), # I add this layer\n",
    "            nn.Conv1d(256, 1536, kernel_size=1),\n",
    "            nn.Softmax(dim=2),\n",
    "            )\n",
    "        self.bn5 = nn.BatchNorm1d(3072)\n",
    "        self.fc6 = nn.Linear(3072, 192)\n",
    "        self.bn6 = nn.BatchNorm1d(192)\n",
    "        self.fc7 = nn.Linear(192, 2)\n",
    "        self.pred2gender = {0 : 'male', 1 : 'female'}\n",
    "\n",
    "    def logtorchfbank(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        # Preemphasis\n",
    "        flipped_filter = torch.FloatTensor([-0.97, 1.]).unsqueeze(0).unsqueeze(0).to(x.device)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.pad(x, (1, 0), 'reflect')\n",
    "        x = F.conv1d(x, flipped_filter).squeeze(1)\n",
    "\n",
    "        # Melspectrogram\n",
    "        x = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=512, win_length=400, hop_length=160, \\\n",
    "                                                 f_min = 20, f_max = 7600, window_fn=torch.hamming_window, n_mels=80).to(x.device)(x) + 1e-6\n",
    "\n",
    "        # Log and normalize\n",
    "        x = x.log()\n",
    "        x = x - torch.mean(x, dim=-1, keepdim=True)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        x = self.logtorchfbank(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x+x1)\n",
    "        x3 = self.layer3(x+x1+x2)\n",
    "\n",
    "        x = self.layer4(torch.cat((x1,x2,x3),dim=1))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        t = x.size()[-1]\n",
    "\n",
    "        global_x = torch.cat((x,torch.mean(x,dim=2,keepdim=True).repeat(1,1,t), torch.sqrt(torch.var(x,dim=2,keepdim=True).clamp(min=1e-4)).repeat(1,1,t)), dim=1)\n",
    "\n",
    "        w = self.attention(global_x)\n",
    "\n",
    "        mu = torch.sum(x * w, dim=2)\n",
    "        sg = torch.sqrt( ( torch.sum((x**2) * w, dim=2) - mu**2 ).clamp(min=1e-4) )\n",
    "\n",
    "        x = torch.cat((mu,sg),1)\n",
    "        x = self.bn5(x)\n",
    "        x = self.fc6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc7(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def load_audio(self, path : str) -> torch.Tensor:\n",
    "        audio, sr = torchaudio.load(path)\n",
    "        if sr != 16000:\n",
    "            audio = resample(audio, sr, 16000)\n",
    "        return audio\n",
    "\n",
    "    def predict(self, audio : torch.Tensor, device: torch.device) -> torch.Tensor:\n",
    "        audio = self.load_audio(audio)\n",
    "        audio = audio.to(device)\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(audio)\n",
    "            _, pred = output.max(1)\n",
    "        return self.pred2gender[pred.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T05:36:10.759965Z",
     "iopub.status.busy": "2024-12-26T05:36:10.759490Z",
     "iopub.status.idle": "2024-12-26T05:36:13.115520Z",
     "shell.execute_reply": "2024-12-26T05:36:13.114777Z",
     "shell.execute_reply.started": "2024-12-26T05:36:10.759931Z"
    },
    "id": "oxQax9ghbH_-",
    "outputId": "51afaf4f-f81d-467e-d31a-6bbd2e886426",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_model = ECAPA_gender.from_pretrained(\"JaesungHuh/voice-gender-classifier\")\n",
    "new_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "new_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T05:36:30.160826Z",
     "iopub.status.busy": "2024-12-26T05:36:30.160547Z",
     "iopub.status.idle": "2024-12-26T05:36:30.514802Z",
     "shell.execute_reply": "2024-12-26T05:36:30.513929Z",
     "shell.execute_reply.started": "2024-12-26T05:36:30.160806Z"
    },
    "id": "uyalAF210-i3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T05:37:57.559863Z",
     "iopub.status.busy": "2024-12-26T05:37:57.559571Z",
     "iopub.status.idle": "2024-12-26T05:37:57.575803Z",
     "shell.execute_reply": "2024-12-26T05:37:57.574957Z",
     "shell.execute_reply.started": "2024-12-26T05:37:57.559842Z"
    },
    "id": "8A0S8GSKnPCc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/data-stereo/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T05:38:02.480101Z",
     "iopub.status.busy": "2024-12-26T05:38:02.479796Z",
     "iopub.status.idle": "2024-12-26T05:38:02.483709Z",
     "shell.execute_reply": "2024-12-26T05:38:02.482977Z",
     "shell.execute_reply.started": "2024-12-26T05:38:02.480078Z"
    },
    "id": "3AAVF82ICitN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T05:38:21.880054Z",
     "iopub.status.busy": "2024-12-26T05:38:21.879754Z",
     "iopub.status.idle": "2024-12-26T05:40:07.647594Z",
     "shell.execute_reply": "2024-12-26T05:40:07.646349Z",
     "shell.execute_reply.started": "2024-12-26T05:38:21.880033Z"
    },
    "id": "M94WZgzD1J7a",
    "outputId": "2c8e606d-fa30-4878-9166-af47f02f4d0c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "  if row['Category'] != 'Gender' and row['Category'] != 'Religion':\n",
    "    audio_path = '../generating_audios/audiogen/' + row['Term'] + \"_\"\n",
    "    # audio_path = '../generating_audios/audioldm/' + row['Term'] + \"_\"\n",
    "    # audio_path = '../generating_audios/stable_audio/' + row['Term'] + \"_\"\n",
    "    for i in range(1, 100):\n",
    "      modified_audio_path = audio_path + str(i) + \".wav\"\n",
    "      with torch.no_grad():\n",
    "        result = new_model.predict(modified_audio_path, device=device)\n",
    "      results_list.append([row['Term'], result])\n",
    "      print(i, [row['Term'], result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T05:41:42.350225Z",
     "iopub.status.busy": "2024-12-26T05:41:42.349925Z",
     "iopub.status.idle": "2024-12-26T05:41:42.353756Z",
     "shell.execute_reply": "2024-12-26T05:41:42.352923Z",
     "shell.execute_reply.started": "2024-12-26T05:41:42.350192Z"
    },
    "id": "Y5k6yLkmMA9u",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T05:41:42.771363Z",
     "iopub.status.busy": "2024-12-26T05:41:42.771077Z",
     "iopub.status.idle": "2024-12-26T05:41:42.779455Z",
     "shell.execute_reply": "2024-12-26T05:41:42.778367Z",
     "shell.execute_reply.started": "2024-12-26T05:41:42.771341Z"
    },
    "id": "blqu4RZLDxJW",
    "outputId": "b9d2c0c0-1586-462b-d14c-62e4235bfc99",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "counts = Counter((role, gender) for role, gender in results_list)\n",
    "\n",
    "role_summary = {}\n",
    "\n",
    "for (role, gender), count in counts.items():\n",
    "    if role not in role_summary:\n",
    "        role_summary[role] = {\"total\": 0, \"male_count\": 0, \"female_count\": 0}\n",
    "\n",
    "    role_summary[role][\"total\"] += count\n",
    "    if gender == \"male\":\n",
    "        role_summary[role][\"male_count\"] += count\n",
    "    elif gender == \"female\":\n",
    "        role_summary[role][\"female_count\"] += count\n",
    "\n",
    "for role, summary in role_summary.items():\n",
    "    male = summary[\"male_count\"]\n",
    "    female = summary[\"female_count\"]\n",
    "    summary[\"male_percentage\"] = (male / (male + female)) * 100\n",
    "\n",
    "result = [\n",
    "    {\n",
    "        \"role\": role,\n",
    "        \"total\": summary[\"total\"],\n",
    "        \"male_count\": summary[\"male_count\"],\n",
    "        \"female_count\": summary[\"female_count\"],\n",
    "        \"male_percentage\": summary[\"male_percentage\"]\n",
    "    }\n",
    "    for role, summary in role_summary.items()\n",
    "]\n",
    "\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_df = pd.DataFrame(result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
